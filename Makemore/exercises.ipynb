{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72676aad-4c6f-4155-9fac-e7239dfb42da",
   "metadata": {},
   "source": [
    "\n",
    "Exercises:\n",
    "- E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
    "- E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "- E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n",
    "- E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels - wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?\n",
    "- E05: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?\n",
    "- E06: meta-exercise! Think of a fun/interesting exercise and complete it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca9955-e891-4228-8b9d-c42a00867292",
   "metadata": {},
   "source": [
    "### Tri-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fc26cc9-68d0-4109-9030-73b286196f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd import MLP\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "295ac3d9-fc76-46ae-85dd-44e587e1598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cb3a5c8-8f93-414f-bf99-4685b09cda47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev: .e\n",
      "next: m\n",
      "prev: em\n",
      "next: m\n",
      "prev: mm\n",
      "next: a\n",
      "prev: ma\n",
      "next: .\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(words[:1])):\n",
    "    if len(words) >= 3:\n",
    "        words[j] = '.' + words[j] + '.'\n",
    "        for i in range(len(words[j])-2):\n",
    "            print(\"prev:\", words[j][i:i+2])\n",
    "            print(\"next:\", words[j][i+2:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39f54ca7-e865-48bf-b374-bf5c5a7aac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = sorted(list(set(''.join(words))))\n",
    "char = ['.'] + char\n",
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a9a3380-3353-488f-90d3-389757f99c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {}\n",
    "for i in range(len(char)):\n",
    "    stoi[char[i]] = i\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c52c3f1c-ac0f-4060-91cf-ee665b8c8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev: 0 5\n",
      "next: 13\n",
      "prev: 5 13\n",
      "next: 13\n",
      "prev: 13 13\n",
      "next: 1\n",
      "prev: 13 1\n",
      "next: 0\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(words[:1])):\n",
    "    if len(words) >= 3:\n",
    "        words[j] = '.' + words[j] + '.'\n",
    "        for i in range(len(words[j])-2):\n",
    "            prev = list(words[j][i:i+2])\n",
    "            after = words[j][i+2:i+3]\n",
    "            print(\"prev:\", stoi[prev[0]], stoi[prev[1]])\n",
    "            print(\"next:\",stoi[after])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50b6ffe4-b63f-4087-ba0c-aa2a9ce13cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset dataset\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccf70aa9-9e9c-42de-b6d7-bf0f2e3a44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for j in range(len(words)):\n",
    "    if len(words) >= 3:\n",
    "        words[j] = '.' + words[j] + '.'\n",
    "        for i in range(len(words[j])-2):\n",
    "            prev = list(words[j][i:i+2])\n",
    "            after = words[j][i+2:i+3]\n",
    "            prev_i = [stoi[prev[0]], stoi[prev[1]]]\n",
    "            after_i = stoi[after]\n",
    "            xs.append(prev_i)\n",
    "            ys.append(after_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3fad192-f812-4f81-b594-6cf41f3fb8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cba1c7f4-4ccc-4a6f-993b-7a0481fd498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63cdfc9a-da7a-42b2-a406-7de997906745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196113, 2]), torch.Size([196113]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d8363a9-36ea-4bdb-a8d9-68dfba22162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = F.one_hot(xs, num_classes=27).float()\n",
    "ys = F.one_hot(ys, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "271c655f-5d3a-4cf7-b347-d6e7004612b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4f079c4-9a1d-4aba-9c20-555b0931fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20ad8e17-49cc-4281-9654-70f314ac6544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196113, 2, 27]), torch.Size([196113, 27]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63719c2f-2bcd-455a-bd4f-7635efeceb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP(27+27,[256,128,27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "242045f5-2cb1-4c8e-be6b-fe8b8fa73ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = torch.cat((xs[0][0], xs[0][1]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fcfa3e9f-2cb0-4189-b120-e09852b98e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nn(input_1, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8923d67f-8f62-4b77-84a9-0b18f919f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=0.0778984180385823, grad=0.0), Value(data=0.011580322410144117, grad=0.0), Value(data=0.06972318294776761, grad=0.0), Value(data=0.010864566736097299, grad=0.0), Value(data=0.010864562968671842, grad=0.0), Value(data=0.010864625567769431, grad=0.0), Value(data=0.010866929679565712, grad=0.0), Value(data=0.011142888558770164, grad=0.0), Value(data=0.051080955801452985, grad=0.0), Value(data=0.0108651013090102, grad=0.0), Value(data=0.010864562815838372, grad=0.0), Value(data=0.010870708093322641, grad=0.0), Value(data=0.08010220623989042, grad=0.0), Value(data=0.011116163215402814, grad=0.0), Value(data=0.07976379436694943, grad=0.0), Value(data=0.010864562811716673, grad=0.0), Value(data=0.08027843369376263, grad=0.0), Value(data=0.08027882042999869, grad=0.0), Value(data=0.08027885961445433, grad=0.0), Value(data=0.013606180874852077, grad=0.0), Value(data=0.06615721400245911, grad=0.0), Value(data=0.03785166511238895, grad=0.0), Value(data=0.010980180178304665, grad=0.0), Value(data=0.07048772056223931, grad=0.0), Value(data=0.0108652130681942, grad=0.0), Value(data=0.05901759806033974, grad=0.0), Value(data=0.010864562842054424, grad=0.0)]\n",
      "27\n",
      "Value(data=1.0000000000000002, grad=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(len(output))\n",
    "print(sum(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9de7bdd-576f-4131-a6e3-b3fdf307f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=4.499355316162109, grad=0.0)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.cross_entropy_loss(output, ys[0])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e3155f1-b730-467b-bf7c-46b12a3d3954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  Value(data=4.499355316162109, grad=0.0)\n",
      "loss:  Value(data=4.581701755523682, grad=0.0)\n",
      "loss:  Value(data=4.050115585327148, grad=0.0)\n",
      "loss:  Value(data=4.640523910522461, grad=0.0)\n",
      "loss:  Value(data=2.778592586517334, grad=0.0)\n",
      "loss:  Value(data=4.103184700012207, grad=0.0)\n",
      "loss:  Value(data=4.720890998840332, grad=0.0)\n",
      "loss:  Value(data=2.8655896186828613, grad=0.0)\n",
      "loss:  Value(data=4.593514919281006, grad=0.0)\n",
      "loss:  Value(data=4.028311252593994, grad=0.0)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "for i in range(len(xs[:10])):\n",
    "    input = torch.cat((xs[i][0], xs[i][1]), dim=0)\n",
    "    label = ys[i]\n",
    "\n",
    "    logits = nn(input, activation=\"softmax\")\n",
    "    loss = nn.cross_entropy_loss(logits, label)\n",
    "    print(\"loss: \", loss)\n",
    "    \n",
    "    # zero grad\n",
    "    for p in nn.parameters():\n",
    "        p.grad = 0.0\n",
    "\n",
    "    # backward   \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in nn.parameters():\n",
    "        p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf341bef-8b5a-4f08-a8f8-d2b7bbb00d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
